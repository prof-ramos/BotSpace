---
title: BotSpace
emoji: "ü§ñ"
colorFrom: blue
colorTo: indigo
sdk: docker
app_port: 7860
pinned: false
---

# BotSpace

Bot para Discord com RAG (Retrieval-Augmented Generation) usando documentos jur√≠dicos, indexa√ß√£o local com FAISS e gera√ß√£o de respostas via Hugging Face Inference API.

## Vis√£o Geral

O projeto combina tres partes principais:

- Bot Discord (`!rag`, `!reindex` e resposta por men√ß√£o)
- API FastAPI para saude, logs e reindexacao
- Pipeline de ingest√£o que baixa documentos, sanitiza arquivos, cria embeddings e publica artefatos de √≠ndice

## Funcionalidades

- Busca sem√¢ntica local com `sentence-transformers` + `faiss-cpu`
- Reindex manual por comando no Discord ou endpoint HTTP
- Recarregamento autom√°tico do √≠ndice em runtime
- Sanitiza√ß√£o de documentos (`.doc` -> `.docx`, remo√ß√£o de formatos n√£o suportados)
- Execu√ß√£o em Docker (compat√≠vel com Hugging Face Spaces)

## Arquitetura

```mermaid
flowchart LR
    A["Discord User"] --> B["Bot (discord.py)"]
    B --> C["LocalIndexRuntime (FAISS)"]
    C --> D["Artifacts locais (faiss.index/meta.json)"]
    B --> E["HF Inference API"]

    F["/reindex (FastAPI)"] --> G["ingest_job.py"]
    G --> H["Dataset de documentos (HF Hub)"]
    G --> I["Dataset de √≠ndice (HF Hub)"]
    G --> D
```

## Pr√©-requisitos

- Python 3.12+
- `uv` instalado
- Ambiente virtual (`.venv`) configurado
- Token de bot do Discord
- Token do Hugging Face com permiss√µes para leitura/escrita nos reposit√≥rios usados

## Quick Start (Local)

1. Criar/ativar ambiente virtual e instalar depend√™ncias com `uv`:

```bash
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt
```

2. Criar `.env` (ou exportar vari√°veis):

```bash
export DISCORD_TOKEN="..."
export REINDEX_API_TOKEN="..."
export HF_TOKEN="..."
export DOCS_REPO_ID="usuario/dataset-documentos"
export INDEX_REPO_ID="usuario/dataset-indice"
export DOCS_SUBDIR="docs_rag"
```

3. Executar:

```bash
python main.py
```

## Configura√ß√£o

| Vari√°vel | Obrigat√≥ria | Default | Descri√ß√£o |
|---|---|---|---|
| `DISCORD_TOKEN` | Sim | - | Token do bot Discord |
| `BOT_PREFIX` | N√£o | `!` | Prefixo de comandos |
| `REINDEX_API_TOKEN` | Nao | - | Se definido, exige Bearer token no `POST /reindex`; se ausente, aceita apenas localhost |
| `HF_TOKEN` | Sim | - | Token para Hugging Face Hub/Inference |
| `HF_TEXT_MODEL` | N√£o | `microsoft/Phi-3.5-mini-instruct` | Modelo de gera√ß√£o de texto |
| `HF_INFERENCE_URL` | N√£o | constru√≠do a partir de `HF_TEXT_MODEL` | URL da Inference API |
| `HF_HOME` | N√£o | autoajustado para diret√≥rio grav√°vel (`/tmp/.huggingface` no Docker) | Diret√≥rio raiz de cache do Hugging Face |
| `HF_HUB_CACHE` | N√£o | `<HF_HOME>/hub` | Diret√≥rio de cache do hub/modelos |
| `DOCS_REPO_ID` | Sim (ingest√£o) | - | Dataset fonte de documentos |
| `INDEX_REPO_ID` | Sim (ingest√£o) | - | Dataset destino dos artefatos de √≠ndice |
| `DOCS_SUBDIR` | N√£o | `docs_rag` | Subdiret√≥rio dos documentos no dataset |
| `EMBED_MODEL` | N√£o | `sentence-transformers/all-MiniLM-L6-v2` | Modelo de embeddings |
| `CHUNK_CHARS` | N√£o | `1200` | Tamanho de chunk |
| `CHUNK_OVERLAP` | N√£o | `200` | Sobreposi√ß√£o de chunks |
| `WORK_DIR` | N√£o | `/tmp/work` (app) / `/tmp/rag_job` (ingest) | Diret√≥rio de trabalho |
| `ARTIFACTS_PREFIX` | N√£o | `artifacts` | Prefixo de arquivos no dataset de √≠ndice |
| `RELOAD_POLL_SECONDS` | N√£o | `30` | Intervalo para detectar atualiza√ß√£o do √≠ndice |
| `REINDEX_EVERY_SECONDS` | N√£o | `0` | Agendamento autom√°tico de reindex (0 desativa) |

## Uso

### Comandos do Bot

- `!rag <pergunta>`: responde com base nos trechos mais relevantes do √≠ndice
- `!reindex` (admin): dispara reindexa√ß√£o
- Men√ß√£o ao bot: responde √† pergunta presente na men√ß√£o

### Endpoints HTTP

- `GET /health` -> `ok`
- `GET /logs` -> √∫ltimos logs da ingest√£o
- `POST /reindex` -> dispara ingest√£o
  - Se `REINDEX_API_TOKEN` estiver definido: requer `Authorization: Bearer <REINDEX_API_TOKEN>`
  - Se `REINDEX_API_TOKEN` nao estiver definido: apenas chamadas de `127.0.0.1`/`::1` sao aceitas

## Docker

Build e run local:

```bash
docker build -t botspace .
docker run --rm -p 7860:7860 \
  -e DISCORD_TOKEN="$DISCORD_TOKEN" \
  -e HF_TOKEN="$HF_TOKEN" \
  -e DOCS_REPO_ID="$DOCS_REPO_ID" \
  -e INDEX_REPO_ID="$INDEX_REPO_ID" \
  botspace
```

Com protecao por token (opcional):

```bash
docker run --rm -p 7860:7860 \
  -e DISCORD_TOKEN="$DISCORD_TOKEN" \
  -e REINDEX_API_TOKEN="$REINDEX_API_TOKEN" \
  -e HF_TOKEN="$HF_TOKEN" \
  -e DOCS_REPO_ID="$DOCS_REPO_ID" \
  -e INDEX_REPO_ID="$INDEX_REPO_ID" \
  botspace
```

> Em ambientes sem volume grav√°vel em `/data`, o container usa `/tmp` por padr√£o e o runtime tenta fallback autom√°tico para um diret√≥rio de cache grav√°vel da Hugging Face.

## Estrutura do Projeto

```text
.
‚îú‚îÄ‚îÄ main.py                 # API FastAPI + scheduler + bootstrap do bot
‚îú‚îÄ‚îÄ bot_app.py              # Bot Discord e comandos
‚îú‚îÄ‚îÄ ingest_job.py           # Pipeline de ingest√£o e publica√ß√£o do √≠ndice
‚îú‚îÄ‚îÄ index_local_runtime.py  # Carregamento/consulta local do √≠ndice
‚îú‚îÄ‚îÄ hf_client.py            # Cliente de infer√™ncia no HF
‚îú‚îÄ‚îÄ sanitize_docs.py        # Convers√£o/sanitiza√ß√£o de documentos
‚îú‚îÄ‚îÄ prompts.py              # Prompt base para respostas
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ docs_rag/               # Base documental local (quando aplic√°vel)
```


## Auditoria de Desempenho (resumo)

### 1) Gargalos identificados

- **Chamada de infer√™ncia sem reutiliza√ß√£o de conex√£o HTTP**: cada request para a API da Hugging Face recriava conex√£o TCP/TLS.
- **Re-embedding de consultas repetidas**: perguntas iguais no bot eram recodificadas a cada busca no FAISS.
- **Janela de reload com potencial de conten√ß√£o**: a checagem de `maybe_reload` ocorria sem proteger atualiza√ß√£o de estado com lock.

### 2) Utiliza√ß√£o de recursos

- **CPU**: carga principal em `SentenceTransformer.encode` (query-time e ingest√£o).
- **Mem√≥ria**: `meta.json` √© carregado integralmente em RAM no runtime; cresce linearmente com n√∫mero de chunks.
- **Rede**: chamadas frequentes para infer√™ncia externa podem acumular lat√™ncia por handshake quando sem sess√£o persistente.

### 3) Efici√™ncia algor√≠tmica

- A busca vetorial est√° em `IndexFlatIP` (custo linear por consulta: `O(N*d)`). Escala bem para volume moderado, mas pode degradar com muitos chunks.
- Chunking √© linear no tamanho dos documentos e adequado para ingest√£o batch.

### 4) Estrat√©gias de cache

- Adotado cache em mem√≥ria para vetores de query (at√© 256 entradas) com invalida√ß√£o autom√°tica ao recarregar √≠ndice.
- Adotada sess√£o HTTP global (`requests.Session`) para reuso de conex√£o na infer√™ncia.

### Recomenda√ß√µes espec√≠ficas de otimiza√ß√£o

1. **Migrar FAISS para √≠ndice aproximado** (`IndexIVFFlat`/`HNSW`) quando `num_chunks` crescer (ex.: > 200k) para reduzir lat√™ncia de busca.
2. **Persistir cache de query com TTL/LRU real** (ex.: `cachetools.TTLCache`) para manter hit-rate com limites previs√≠veis.
3. **Compactar e segmentar metadados** (ex.: `orjson` + shards) para reduzir pico de RAM no `load()`.
4. **Paralelizar parsing de documentos** na ingest√£o (pool por arquivo) para diminuir tempo total de reindexa√ß√£o.
5. **Instrumentar m√©tricas** (P95 de `search`, tempo de `call_hf`, uso de mem√≥ria do processo) e definir alertas.

## Troubleshooting

- Erro `HF_TOKEN nao definido`: exporte `HF_TOKEN` antes de iniciar.
- Erro `DISCORD_TOKEN nao definido`: verifique token do bot e permiss√µes no servidor.
- `Indice nao existe ... Rode reindex primeiro.`: execute `!reindex` ou `POST /reindex`.
- Falha com `.doc`: garanta LibreOffice/`soffice` dispon√≠vel (j√° incluso no Dockerfile).
- Erro de permiss√£o em cache HF (`PermissionError: /data`): defina `HF_HOME`/`HF_HUB_CACHE` para um diret√≥rio grav√°vel (ex.: `/tmp/.huggingface`) ou deixe o fallback autom√°tico configurar.

## Contribui√ß√£o

1. Crie uma branch para sua altera√ß√£o.
2. Fa√ßa mudan√ßas pequenas e test√°veis.
3. Abra PR com contexto, impacto e forma de valida√ß√£o.

## Licen√ßa

Defina a licen√ßa do projeto (ex.: MIT) e adicione o arquivo `LICENSE` no reposit√≥rio.
